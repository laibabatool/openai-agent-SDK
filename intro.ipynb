{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7prlvy7d2ul",
        "outputId": "1017c996-875a-4677-e41a-07e6bc4bd74c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-agents in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: griffe<2,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.7.3)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.11.0)\n",
            "Requirement already satisfied: openai<2,>=1.96.1 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.97.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Requirement already satisfied: types-requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.4.20250611)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.14.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.9.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.24.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.4.1)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.47.1)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.96.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.26.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n"
          ]
        }
      ],
      "source": [
        "pip install openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cb80370"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the OpenAI API key from Colab secrets\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "nLwtD9EDk-7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents\n"
      ],
      "metadata": {
        "id": "fcA1Qk_foAQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "result =  Runner.run_sync(agent, \"Write a haiku about recursion in programming.\") #(starting agent, user_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUC9OrCA1-qi",
        "outputId": "373ce9cd-a06e-4238-b4c8-67b6ec00651b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code within the code,  \n",
            "Loops call themselves endlesslyâ€”  \n",
            "Depth in simple form.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents with Tracing"
      ],
      "metadata": {
        "id": "ndMB-AqvoChw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "from agents import enable_verbose_stdout_logging\n",
        "\n",
        "\n",
        "enable_verbose_stdout_logging()\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "result =  Runner.run_sync(agent, \"Write a haiku about recursion in programming.\") #(starting agent, user_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i0H1Jr6e2s7",
        "outputId": "3cfaab3f-755a-4269-b754-ff5442d955a1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating trace Agent workflow with id trace_84ccd46417d84f2bb32dc409282dfeff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating trace Agent workflow with id trace_84ccd46417d84f2bb32dc409282dfeff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting current trace: trace_84ccd46417d84f2bb32dc409282dfeff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Setting current trace: trace_84ccd46417d84f2bb32dc409282dfeff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x7cd87bb23350> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x7cd87bb23350> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Assistant (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Assistant (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7cd87ba869e0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7cd87ba869e0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"Write a haiku about recursion in programming.\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"Write a haiku about recursion in programming.\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878d18e3598819c8e8b834402d25968086f2c8415df9e0c\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"Code calls on itself,  \\nNested loops weave through the depthsâ€”  \\nInfinite echoes.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878d18e3598819c8e8b834402d25968086f2c8415df9e0c\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"Code calls on itself,  \\nNested loops weave through the depthsâ€”  \\nInfinite echoes.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code calls on itself,  \n",
            "Nested loops weave through the depthsâ€”  \n",
            "Infinite echoes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in tracing we have two things ( tracing + span)\n",
        "#Trace:    [ User prompt â†’ LLM â†’ Function call â†’ Result â†’ Output ]\n",
        "#Spans:      â””â”€ Span 1      â””â”€ Span 2       â””â”€ Span 3   â””â”€ Span 4\n"
      ],
      "metadata": {
        "id": "4lhk7BrEqLIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input to llm -> system prompt, user prompt, tools schema, tool message\n",
        "# output from llm -> plan text, which tool to call"
      ],
      "metadata": {
        "id": "mq6Fv16LmVvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool calling"
      ],
      "metadata": {
        "id": "2f7uMIjboFZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, function_tool\n",
        "from agents import enable_verbose_stdout_logging\n",
        "\n",
        "\n",
        "enable_verbose_stdout_logging()\n",
        "\n",
        "@function_tool\n",
        "def weather(city: str) -> str:\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "agent = Agent(name=\"Assistant\", tools=[weather])\n",
        "\n",
        "result =  Runner.run_sync(agent, \"what is weather in karachi?\") #(starting agent, user_input)\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y-5fZ78LmlPn",
        "outputId": "26a59f35-30e9-4183-b970-897eaa1292d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating trace Agent workflow with id trace_a4235db9565e4165805ae89f7c3db3f1\n",
            "Creating trace Agent workflow with id trace_a4235db9565e4165805ae89f7c3db3f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating trace Agent workflow with id trace_a4235db9565e4165805ae89f7c3db3f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting current trace: trace_a4235db9565e4165805ae89f7c3db3f1\n",
            "Setting current trace: trace_a4235db9565e4165805ae89f7c3db3f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Setting current trace: trace_a4235db9565e4165805ae89f7c3db3f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x7d77f58dadb0> with id None\n",
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x7d77f58dadb0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x7d77f58dadb0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Assistant (turn 1)\n",
            "Running agent Assistant (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Assistant (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7d77f593e170> with id None\n",
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7d77f593e170> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7d77f593e170> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is weather in karachi?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"weather\",\n",
            "    \"parameters\": {\n",
            "      \"properties\": {\n",
            "        \"city\": {\n",
            "          \"title\": \"City\",\n",
            "          \"type\": \"string\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"city\"\n",
            "      ],\n",
            "      \"title\": \"weather_args\",\n",
            "      \"type\": \"object\",\n",
            "      \"additionalProperties\": false\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n",
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is weather in karachi?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"weather\",\n",
            "    \"parameters\": {\n",
            "      \"properties\": {\n",
            "        \"city\": {\n",
            "          \"title\": \"City\",\n",
            "          \"type\": \"string\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"city\"\n",
            "      ],\n",
            "      \"title\": \"weather_args\",\n",
            "      \"type\": \"object\",\n",
            "      \"additionalProperties\": false\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is weather in karachi?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"weather\",\n",
            "    \"parameters\": {\n",
            "      \"properties\": {\n",
            "        \"city\": {\n",
            "          \"title\": \"City\",\n",
            "          \"type\": \"string\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"city\"\n",
            "      ],\n",
            "      \"title\": \"weather_args\",\n",
            "      \"type\": \"object\",\n",
            "      \"additionalProperties\": false\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"arguments\": \"{\\\"city\\\":\\\"karachi\\\"}\",\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"name\": \"weather\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_68780679518481a3b1238a2cd0f0e1fc07f2ed773e76d508\",\n",
            "    \"status\": \"completed\"\n",
            "  }\n",
            "]\n",
            "\n",
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"arguments\": \"{\\\"city\\\":\\\"karachi\\\"}\",\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"name\": \"weather\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_68780679518481a3b1238a2cd0f0e1fc07f2ed773e76d508\",\n",
            "    \"status\": \"completed\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"arguments\": \"{\\\"city\\\":\\\"karachi\\\"}\",\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"name\": \"weather\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_68780679518481a3b1238a2cd0f0e1fc07f2ed773e76d508\",\n",
            "    \"status\": \"completed\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x7d77f58db590> with id None\n",
            "Creating span <agents.tracing.span_data.FunctionSpanData object at 0x7d77f58db590> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.FunctionSpanData object at 0x7d77f58db590> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invoking tool weather with input {\"city\":\"karachi\"}\n",
            "Invoking tool weather with input {\"city\":\"karachi\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Invoking tool weather with input {\"city\":\"karachi\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool call args: ['karachi'], kwargs: {}\n",
            "Tool call args: ['karachi'], kwargs: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tool call args: ['karachi'], kwargs: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool weather returned The weather in karachi is sunny.\n",
            "Tool weather returned The weather in karachi is sunny.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tool weather returned The weather in karachi is sunny.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Assistant (turn 2)\n",
            "Running agent Assistant (turn 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Assistant (turn 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7d77f593cd20> with id None\n",
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7d77f593cd20> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7d77f593cd20> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is weather in karachi?\",\n",
            "    \"role\": \"user\"\n",
            "  },\n",
            "  {\n",
            "    \"arguments\": \"{\\\"city\\\":\\\"karachi\\\"}\",\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"name\": \"weather\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_68780679518481a3b1238a2cd0f0e1fc07f2ed773e76d508\",\n",
            "    \"status\": \"completed\"\n",
            "  },\n",
            "  {\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"output\": \"The weather in karachi is sunny.\",\n",
            "    \"type\": \"function_call_output\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"weather\",\n",
            "    \"parameters\": {\n",
            "      \"properties\": {\n",
            "        \"city\": {\n",
            "          \"title\": \"City\",\n",
            "          \"type\": \"string\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"city\"\n",
            "      ],\n",
            "      \"title\": \"weather_args\",\n",
            "      \"type\": \"object\",\n",
            "      \"additionalProperties\": false\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n",
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is weather in karachi?\",\n",
            "    \"role\": \"user\"\n",
            "  },\n",
            "  {\n",
            "    \"arguments\": \"{\\\"city\\\":\\\"karachi\\\"}\",\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"name\": \"weather\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_68780679518481a3b1238a2cd0f0e1fc07f2ed773e76d508\",\n",
            "    \"status\": \"completed\"\n",
            "  },\n",
            "  {\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"output\": \"The weather in karachi is sunny.\",\n",
            "    \"type\": \"function_call_output\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"weather\",\n",
            "    \"parameters\": {\n",
            "      \"properties\": {\n",
            "        \"city\": {\n",
            "          \"title\": \"City\",\n",
            "          \"type\": \"string\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"city\"\n",
            "      ],\n",
            "      \"title\": \"weather_args\",\n",
            "      \"type\": \"object\",\n",
            "      \"additionalProperties\": false\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is weather in karachi?\",\n",
            "    \"role\": \"user\"\n",
            "  },\n",
            "  {\n",
            "    \"arguments\": \"{\\\"city\\\":\\\"karachi\\\"}\",\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"name\": \"weather\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_68780679518481a3b1238a2cd0f0e1fc07f2ed773e76d508\",\n",
            "    \"status\": \"completed\"\n",
            "  },\n",
            "  {\n",
            "    \"call_id\": \"call_mjjLgy3SDwAexqSXkoFq5XOz\",\n",
            "    \"output\": \"The weather in karachi is sunny.\",\n",
            "    \"type\": \"function_call_output\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"weather\",\n",
            "    \"parameters\": {\n",
            "      \"properties\": {\n",
            "        \"city\": {\n",
            "          \"title\": \"City\",\n",
            "          \"type\": \"string\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"city\"\n",
            "      ],\n",
            "      \"title\": \"weather_args\",\n",
            "      \"type\": \"object\",\n",
            "      \"additionalProperties\": false\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878067a037081a3bd8731e0fdb68ef607f2ed773e76d508\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"The weather in Karachi is sunny.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n",
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878067a037081a3bd8731e0fdb68ef607f2ed773e76d508\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"The weather in Karachi is sunny.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878067a037081a3bd8731e0fdb68ef607f2ed773e76d508\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"The weather in Karachi is sunny.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetting current trace\n",
            "Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Karachi is sunny.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents, Handsoff and Guardrails"
      ],
      "metadata": {
        "id": "Vyyw5HRKoIKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, InputGuardrail, GuardrailFunctionOutput, Runner\n",
        "from pydantic import BaseModel\n",
        "import asyncio\n",
        "from agents import enable_verbose_stdout_logging\n",
        "\n",
        "\n",
        "enable_verbose_stdout_logging()\n",
        "\n",
        "class HomeworkOutput(BaseModel):\n",
        "    is_homework: bool\n",
        "    reasoning: str\n",
        "\n",
        "guardrail_agent = Agent(\n",
        "    name=\"Guardrail check\",\n",
        "    instructions=\"Check if the user is asking about homework.\",\n",
        "    output_type=HomeworkOutput,\n",
        ")\n",
        "\n",
        "math_tutor_agent = Agent(\n",
        "    name=\"Math Tutor\",\n",
        "    handoff_description=\"Specialist agent for math questions\",\n",
        "    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n",
        ")\n",
        "\n",
        "history_tutor_agent = Agent(\n",
        "    name=\"History Tutor\",\n",
        "    handoff_description=\"Specialist agent for historical questions\",\n",
        "    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n",
        ")\n",
        "\n",
        "\n",
        "async def homework_guardrail(ctx, agent, input_data):\n",
        "    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n",
        "    final_output = result.final_output_as(HomeworkOutput)\n",
        "    return GuardrailFunctionOutput(\n",
        "        output_info=final_output,\n",
        "        tripwire_triggered=not final_output.is_homework,\n",
        "    )\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=\"You determine which agent to use based on the user's homework question\",\n",
        "    handoffs=[history_tutor_agent, math_tutor_agent],\n",
        "    input_guardrails=[\n",
        "        InputGuardrail(guardrail_function=homework_guardrail),\n",
        "    ],\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(triage_agent, \"who was the first president of the united states?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "    result = await Runner.run(triage_agent, \"what is life\")\n",
        "    print(result.final_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7XG0yWtV5iU1",
        "outputId": "ec67ed36-2061-4fc7-a33b-232ffb60c360",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating trace Agent workflow with id trace_e3080afa6d714fb9ab403cd3659f4987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating trace Agent workflow with id trace_e3080afa6d714fb9ab403cd3659f4987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting current trace: trace_e3080afa6d714fb9ab403cd3659f4987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Setting current trace: trace_e3080afa6d714fb9ab403cd3659f4987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685baa750> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685baa750> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Triage Agent (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Triage Agent (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.GuardrailSpanData object at 0x7816859eccd0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.GuardrailSpanData object at 0x7816859eccd0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685172390> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685172390> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Guardrail check (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Guardrail check (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7816bc0c6a30> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7816bc0c6a30> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"who was the first president of the united states?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: {'format': {'type': 'json_schema', 'name': 'final_output', 'schema': {'properties': {'is_homework': {'title': 'Is Homework', 'type': 'boolean'}, 'reasoning': {'title': 'Reasoning', 'type': 'string'}}, 'required': ['is_homework', 'reasoning'], 'title': 'HomeworkOutput', 'type': 'object', 'additionalProperties': False}, 'strict': True}}\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"who was the first president of the united states?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: {'format': {'type': 'json_schema', 'name': 'final_output', 'schema': {'properties': {'is_homework': {'title': 'Is Homework', 'type': 'boolean'}, 'reasoning': {'title': 'Reasoning', 'type': 'string'}}, 'required': ['is_homework', 'reasoning'], 'title': 'HomeworkOutput', 'type': 'object', 'additionalProperties': False}, 'strict': True}}\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x781685a9c050> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x781685a9c050> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"who was the first president of the united states?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the History Tutor agent to handle the request. Specialist agent for historical questions\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"transfer_to_math_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the Math Tutor agent to handle the request. Specialist agent for math questions\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"who was the first president of the united states?\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the History Tutor agent to handle the request. Specialist agent for historical questions\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"transfer_to_math_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the Math Tutor agent to handle the request. Specialist agent for math questions\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"arguments\": \"{}\",\n",
            "    \"call_id\": \"call_LECSmBgZHRTStdIuX7X5ivYO\",\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_6878e5ed2df881a1b9b2a17caa6924b600d23641a7a4d691\",\n",
            "    \"status\": \"completed\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"arguments\": \"{}\",\n",
            "    \"call_id\": \"call_LECSmBgZHRTStdIuX7X5ivYO\",\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_6878e5ed2df881a1b9b2a17caa6924b600d23641a7a4d691\",\n",
            "    \"status\": \"completed\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.HandoffSpanData object at 0x7816bc0c57c0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.HandoffSpanData object at 0x7816bc0c57c0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878e5ec9434819d933787e89459d5c8004c74098c361d1b\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"{\\\"is_homework\\\":true,\\\"reasoning\\\":\\\"The question about historical facts, especially something as commonly asked in educational environments as the first president of the United States, is likely to be homework-related. Such questions are often part of school assignments or quizzes.\\\"}\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878e5ec9434819d933787e89459d5c8004c74098c361d1b\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"{\\\"is_homework\\\":true,\\\"reasoning\\\":\\\"The question about historical facts, especially something as commonly asked in educational environments as the first president of the United States, is likely to be homework-related. Such questions are often part of school assignments or quizzes.\\\"}\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685172cf0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685172cf0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent History Tutor (turn 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent History Tutor (turn 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7816860fed00> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7816860fed00> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"who was the first president of the united states?\",\n",
            "    \"role\": \"user\"\n",
            "  },\n",
            "  {\n",
            "    \"arguments\": \"{}\",\n",
            "    \"call_id\": \"call_LECSmBgZHRTStdIuX7X5ivYO\",\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_6878e5ed2df881a1b9b2a17caa6924b600d23641a7a4d691\",\n",
            "    \"status\": \"completed\"\n",
            "  },\n",
            "  {\n",
            "    \"call_id\": \"call_LECSmBgZHRTStdIuX7X5ivYO\",\n",
            "    \"output\": \"{\\\"assistant\\\": \\\"History Tutor\\\"}\",\n",
            "    \"type\": \"function_call_output\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"who was the first president of the united states?\",\n",
            "    \"role\": \"user\"\n",
            "  },\n",
            "  {\n",
            "    \"arguments\": \"{}\",\n",
            "    \"call_id\": \"call_LECSmBgZHRTStdIuX7X5ivYO\",\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"type\": \"function_call\",\n",
            "    \"id\": \"fc_6878e5ed2df881a1b9b2a17caa6924b600d23641a7a4d691\",\n",
            "    \"status\": \"completed\"\n",
            "  },\n",
            "  {\n",
            "    \"call_id\": \"call_LECSmBgZHRTStdIuX7X5ivYO\",\n",
            "    \"output\": \"{\\\"assistant\\\": \\\"History Tutor\\\"}\",\n",
            "    \"type\": \"function_call_output\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878e5ee2cdc81a1bc756437244c56bd00d23641a7a4d691\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"The first President of the United States was George Washington. He served from 1789 to 1797. Washington was a key figure in the American Revolutionary War and was known for his leadership and integrity. He is often called the \\\\\\\"Father of His Country\\\\\\\" for his role in the founding of the United States. Washington set many precedents for the presidency, including the tradition of serving only two terms.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878e5ee2cdc81a1bc756437244c56bd00d23641a7a4d691\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"The first President of the United States was George Washington. He served from 1789 to 1797. Washington was a key figure in the American Revolutionary War and was known for his leadership and integrity. He is often called the \\\\\\\"Father of His Country\\\\\\\" for his role in the founding of the United States. Washington set many precedents for the presidency, including the tradition of serving only two terms.\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first President of the United States was George Washington. He served from 1789 to 1797. Washington was a key figure in the American Revolutionary War and was known for his leadership and integrity. He is often called the \\\"Father of His Country\\\" for his role in the founding of the United States. Washington set many precedents for the presidency, including the tradition of serving only two terms.\n",
            "Creating trace Agent workflow with id trace_6c1b314597c643e188b963d539d3a5b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating trace Agent workflow with id trace_6c1b314597c643e188b963d539d3a5b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting current trace: trace_6c1b314597c643e188b963d539d3a5b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Setting current trace: trace_6c1b314597c643e188b963d539d3a5b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x7816851730b0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x7816851730b0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Triage Agent (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Triage Agent (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.GuardrailSpanData object at 0x78168517b020> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.GuardrailSpanData object at 0x78168517b020> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685173830> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.AgentSpanData object at 0x781685173830> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Guardrail check (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Guardrail check (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7816859edae0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x7816859edae0> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is life\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: {'format': {'type': 'json_schema', 'name': 'final_output', 'schema': {'properties': {'is_homework': {'title': 'Is Homework', 'type': 'boolean'}, 'reasoning': {'title': 'Reasoning', 'type': 'string'}}, 'required': ['is_homework', 'reasoning'], 'title': 'HomeworkOutput', 'type': 'object', 'additionalProperties': False}, 'strict': True}}\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is life\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: {'format': {'type': 'json_schema', 'name': 'final_output', 'schema': {'properties': {'is_homework': {'title': 'Is Homework', 'type': 'boolean'}, 'reasoning': {'title': 'Reasoning', 'type': 'string'}}, 'required': ['is_homework', 'reasoning'], 'title': 'HomeworkOutput', 'type': 'object', 'additionalProperties': False}, 'strict': True}}\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating span <agents.tracing.span_data.ResponseSpanData object at 0x781685a9c820> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Creating span <agents.tracing.span_data.ResponseSpanData object at 0x781685a9c820> with id None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is life\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the History Tutor agent to handle the request. Specialist agent for historical questions\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"transfer_to_math_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the Math Tutor agent to handle the request. Specialist agent for math questions\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Calling LLM gpt-4o with input:\n",
            "[\n",
            "  {\n",
            "    \"content\": \"what is life\",\n",
            "    \"role\": \"user\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"transfer_to_history_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the History Tutor agent to handle the request. Specialist agent for historical questions\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"transfer_to_math_tutor\",\n",
            "    \"parameters\": {\n",
            "      \"additionalProperties\": false,\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {},\n",
            "      \"required\": []\n",
            "    },\n",
            "    \"strict\": true,\n",
            "    \"type\": \"function\",\n",
            "    \"description\": \"Handoff to the Math Tutor agent to handle the request. Specialist agent for math questions\"\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "Previous response id: None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported 10 items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Exported 10 items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878e5f098ec8191ae1488f4f13520460634a8f44b48d225\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"{\\\"is_homework\\\":false,\\\"reasoning\\\":\\\"The question is philosophical in nature and seeks a broad, existential understanding, not related to an academic or homework assignment.\\\"}\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "[\n",
            "  {\n",
            "    \"id\": \"msg_6878e5f098ec8191ae1488f4f13520460634a8f44b48d225\",\n",
            "    \"content\": [\n",
            "      {\n",
            "        \"annotations\": [],\n",
            "        \"text\": \"{\\\"is_homework\\\":false,\\\"reasoning\\\":\\\"The question is philosophical in nature and seeks a broad, existential understanding, not related to an academic or homework assignment.\\\"}\",\n",
            "        \"type\": \"output_text\",\n",
            "        \"logprobs\": []\n",
            "      }\n",
            "    ],\n",
            "    \"role\": \"assistant\",\n",
            "    \"status\": \"completed\",\n",
            "    \"type\": \"message\"\n",
            "  }\n",
            "]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Resetting current trace\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InputGuardrailTripwireTriggered",
          "evalue": "Guardrail InputGuardrail triggered tripwire",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInputGuardrailTripwireTriggered\u001b[0m           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-1678347776.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-1678347776.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriage_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"what is life\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, session)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_AGENT_RUNNER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         return await runner.run(\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mstarting_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, starting_agent, input, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         input_guardrail_results, turn_result = await asyncio.gather(\n\u001b[0m\u001b[1;32m    413\u001b[0m                             self._run_input_guardrails(\n\u001b[1;32m    414\u001b[0m                                 \u001b[0mstarting_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/run.py\u001b[0m in \u001b[0;36m_run_input_guardrails\u001b[0;34m(cls, agent, guardrails, input, context)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                     )\n\u001b[1;32m   1057\u001b[0m                 )\n\u001b[0;32m-> 1058\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mInputGuardrailTripwireTriggered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m                 \u001b[0mguardrail_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInputGuardrailTripwireTriggered\u001b[0m: Guardrail InputGuardrail triggered tripwire"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hello(name:str) -> str:\n",
        "    print(\"hello\",name)"
      ],
      "metadata": {
        "id": "00WECdUgDsU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hello(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_uUPvZHDyzh",
        "outputId": "4254149b-f241-4def-980c-540b7ff6caaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result with Streaming\n",
        "\n"
      ],
      "metadata": {
        "id": "lwS_4FRWNyPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "from agents import enable_verbose_stdout_logging\n",
        "import asyncio\n",
        "\n",
        "#enable_verbose_stdout_logging()\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "async def stream_agent():\n",
        "    result =  Runner.run_streamed(agent, \"Write a haiku about recursion in programming.\") #(starting agent, user_input)\n",
        "\n",
        "    async for event in result.stream_events():\n",
        "        print(event)\n",
        "        await asyncio.sleep(30) # Add a small delay\n",
        "\n",
        "asyncio.run(stream_agent())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "fJB7TUsqNvbZ",
        "outputId": "5c5f0f59-9d71-4b2a-a71c-fd4009d3581b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgentUpdatedStreamEvent(new_agent=Agent(name='Assistant', handoff_description=None, tools=[], mcp_servers=[], mcp_config={}, instructions='You are a helpful assistant', prompt=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, response_include=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), type='agent_updated_stream_event')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-1902193676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add a small delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 scheduled[0]._when - self.time(), 0), 86400) if scheduled\n\u001b[1;32m    114\u001b[0m             else None)\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mevent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}